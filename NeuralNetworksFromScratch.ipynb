{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0cf6d230331099d4773a6137a56c3541746da970bab15c4b63349a6079cb56b25",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Examples from Chapter 5 of Natural Languge Processing in Action Text Book\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.674"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "import numpy as np\n",
    "example_input=[1,.2,.1,.05,.2]\n",
    "example_weights=[.2, .12, .4, .6, .90]\n",
    "input_vector=np.array(example_input)\n",
    "weights=np.array(example_weights)\n",
    "bias_weight=.2\n",
    "\n",
    "activation_level=np.dot(input_vector,weights) + (bias_weight*1)\n",
    "\n",
    "activation_level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "threshold=0.5\n",
    "if activation_level >= threshold:\n",
    "    perceptron_output=1\n",
    "else:\n",
    "    perceptron_output=0\n",
    "\n",
    "perceptron_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.2, 0.12, 0.4, 0.6, 0.9]\n[-1.8  -0.28  0.2   0.5   0.5 ]\n"
     ]
    }
   ],
   "source": [
    "#the output above was 1, what if the expected output was 0, how are the weights impacted?\n",
    "expected_output=0\n",
    "new_weights=[]\n",
    "for i, x in enumerate(example_input): #an enumerate object is created, allows access to value and index of object\n",
    "    #print(i,x)\n",
    "    new_weights.append(weights[i]+(expected_output-perceptron_output)*x)\n",
    "weights=np.array(new_weights)\n",
    "\n",
    "print(example_weights)\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "source": [
    "### Toy Example: Teach Computer concept of logical OR "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "random weights:  [0.00074816 0.00023567]\nbias:0.0009663059857283813\n"
     ]
    }
   ],
   "source": [
    "sample_data = [[0, 0], # False, False\n",
    "[0, 1], # False, True\n",
    "[1, 0], # True, False\n",
    "[1, 1]] # True, True\n",
    "\n",
    "# for toy example you can list out the expected outputs although in real life this is never the case\n",
    "expected_results = [0, # (False OR False) gives False\n",
    "1, # (False OR True ) gives True\n",
    "1, # (True OR False) gives True\n",
    "1] # (True OR True ) gives True\n",
    "activation_threshold = 0.5\n",
    "\n",
    "from random import random\n",
    "import numpy as np\n",
    "\n",
    "weights=np.random.random(2)/1000 # 2 small random floats divided by 1000 0<w<0.001\n",
    "print(f'random weights:  {weights}')\n",
    "bias_weight=np.random.random()/1000 #return 1 small random float divided by 1000\n",
    "print(f'bias:{bias_weight}')\n",
    "# f-strings allow you to insert values into string w/o type conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "activation_level:0.00038571589499265493\nPredicted: 0\nExpected: 0\n\nactivation_level:0.001007299481575885\nPredicted: 0\nExpected: 1\n\nactivation_level:0.0007039561096697046\nPredicted: 0\nExpected: 1\n\nactivation_level:0.0013255396962529346\nPredicted: 0\nExpected: 1\n\n"
     ]
    }
   ],
   "source": [
    "for idx, sample in enumerate(sample_data):\n",
    "    input_vector=np.array(sample)\n",
    "    activation_level=np.dot(input_vector, weights)+(bias_weight*1)\n",
    "    print(f'activation_level:{activation_level}')\n",
    "    if activation_level>activation_threshold:\n",
    "        perceptron_output=1\n",
    "    else:\n",
    "        perceptron_output=0\n",
    "    print(f'Predicted: {perceptron_output}')\n",
    "    print(f'Expected: {expected_results[idx]}')\n",
    "    print()"
   ]
  },
  {
   "source": [
    "As can be seen above, 1 right, 3 wrong, the random weights didn't help the neuron to go over the activation level.\n",
    "Now we're gong to update the weights at each iteration\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "random weights:  [0.00046365 0.00018554]\nbias:0.00041807111694479413\n\n2.0010672613500624 activation level and threshold 0.5 for iteration 0\n3 correct answers out of 4, for iteration 0\n\n3.0010672613500624 activation level and threshold 0.5 for iteration 1\n2 correct answers out of 4, for iteration 1\n\n2.0010672613500624 activation level and threshold 0.5 for iteration 2\n3 correct answers out of 4, for iteration 2\n\n2.0010672613500624 activation level and threshold 0.5 for iteration 3\n4 correct answers out of 4, for iteration 3\n\n2.0010672613500624 activation level and threshold 0.5 for iteration 4\n4 correct answers out of 4, for iteration 4\n\n"
     ]
    }
   ],
   "source": [
    "sample_data = [[0, 0], # False, False\n",
    "[0, 1], # False, True\n",
    "[1, 0], # True, False\n",
    "[1, 1]] # True, True\n",
    "\n",
    "# for toy example you can list out the expected outputs although in real life this is never the case\n",
    "expected_results = [0, # (False OR False) gives False\n",
    "1, # (False OR True ) gives True\n",
    "1, # (True OR False) gives True\n",
    "1] # (True OR True ) gives True\n",
    "activation_threshold = 0.5\n",
    "\n",
    "from random import random\n",
    "import numpy as np\n",
    "\n",
    "weights=np.random.random(2)/1000 # 2 small random floats divided by 1000 0<w<0.001\n",
    "print(f'random weights:  {weights}')\n",
    "bias_weight=np.random.random()/1000 #return 1 small random float divided by 1000\n",
    "print(f'bias:{bias_weight}')\n",
    "print()\n",
    "# f-strings allow you to insert values into string w/o type conversion\n",
    "\n",
    "\n",
    "for iteration_num in range(5):\n",
    "    correct_answers=0\n",
    "    for idx, sample in enumerate(sample_data):\n",
    "        #print (idx,sample)\n",
    "        input_vector= sample\n",
    "        weights=np.array(weights)\n",
    "        activation_level=np.dot(input_vector, weights)+(bias_weight*1)\n",
    "        if activation_level>activation_threshold:\n",
    "            perceptron_output=1\n",
    "        else:\n",
    "            perceptron_output=0\n",
    "        if perceptron_output==expected_results[idx]:\n",
    "            correct_answers+=1\n",
    "        new_weights=[]\n",
    "        for i, x in enumerate(sample):\n",
    "            new_weights.append(weights[i]+(expected_results[idx]-perceptron_output)*x)\n",
    "        bias_weight=bias_weight+((expected_results[idx]-perceptron_output)*1)\n",
    "        weights=np.array(new_weights)\n",
    "    print(f'{activation_level} activation level and threshold {activation_threshold} for iteration {iteration_num}')\n",
    "    print(f'{correct_answers} correct answers out of 4, for iteration {iteration_num}')\n",
    "    print()"
   ]
  },
  {
   "source": [
    "The perceptron converged to a value for the weights that returned the correct results after 5 iterations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}